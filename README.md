# Interpretable Network Visualizations
All results obtained in the paper [*M. Bianchi, A. De Santis, A. Tocchetti and M. Brambilla: Interpretable Network Visualizations: A Human-in-the-Loop Approach for Post-hoc Explainability of CNN-based Image Classification*]() are provided in this repository

## Additional Resources
In this folder we collected all images and visualizations for both global and local explanations for all classes used in the presented experiment.
- For local explanations, we provide an HTML file to ease the visualization process. With such, it is possible to select the class, the image and whether to apply the label merging algorithm or not. Additionally, all compressed explanations (i.e., heatmap, score and the top 3 labels) can be clicked to access the expanded visualization about the cluster map.
- For global explanations, we provide explanations by class and by layer in the form of png images.

## Code
In this folder we provide the code we used in the different phases of the experiment, including tests not presented in the paper (i.e., the code for different clustering algorithms and additional plots for label analysis).

## *Deep Reveal* Screenshots
In this folder we collected screenshots of the *Deep Reveal* application, as well as an IFML diagram describing its pipeline.

## Questionnaires
In this form we present the forms and some additional results regarding the questionnaires discussed in the main paper.
